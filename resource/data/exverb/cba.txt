To train a system that can identify terms and their definitions in scientific articles. Our system DefMiner achieves 85% F1 on a Wikipedia benchmark corpus, significantly improving the previous state-of-the-art by 8%. We exploit DefMiner to process the ACL Anthology Reference Corpus (ARC) – a large, real-world digital library of scientific articles in computational linguistics. The resulting automatically-acquired glossary represents the terminology defined over several thousand individual research articles.

This paper studies the importance of identifying and categorizing scientific concepts as a way to achieve a deeper understanding of the research literature of a scientific community.
To reach this goal, we propose an unsupervised bootstrapping algorithm for identifying and categorizing mentions of concepts.
We then propose a new clustering algorithm that uses citations’ context as a way to cluster the extracted mentions into coherent concepts. 
Our evaluation of the algorithms against gold standards shows significant improvement over state-of-the-art results. 
More importantly, we analyze the computational linguistic literature using the proposed algorithms and show four different ways to summarize and understand the research community which are difficult to obtain using existing techniques.

The dramatic growth in scientific communities and the publication trace they generate brought with it the challenge of understanding a scientific community – identifying important concepts, trends, key techniques, applications and the relations between them – by analyzing the publication trace.

Earlier studies of this question made use of bibliometrics techniques, mostly considering citation graphs [12] and topic models, forming crude topic clustering based on contextual cues [1, 16].

However, these methods cannot address some key questions such as “what methods were developed to solve a particular problem?”, “how did these change over the years?”, and “what applications have matured enough to be used as components of other applications?” 

In this paper, we propose that if we want to achieve a deeper understanding of a scientific community from the paper trace generated by the community, there is a need to better analyze the text itself; there is a need to identify mentions of scientific concepts, categorize them and cluster them into coherent concepts, and study the relations between concepts of various categories.
We develop methods to do that, and our evaluation on the ACL text collection reveals interesting observations and insights on the Computational Linguistics scientific community.

The most basic component of our model is an unsupervised algorithm that identifies mentions of concepts; in this paper we focus on two categories of concepts: TECHNIQUEs and APPLICATIONs.
For example, in the sentence “We apply support vector machines on text classification.” our goal is to identify “support vector machines” as a TECHNIQUE and “text classification” as an APPLICATION.
We define the concept extraction problem in a way that is similar to the named entity recognition problem. This instance of the problem was also studied earlier in [5]. Our first contribution is a bootstrapping algorithm [20, 3] that makes use of a small number of per-category pre-specified seeds. 

The algorithm is used to induce a decision list of features for each category, that is used, in turn, to annotate mentions as belonging to the category and then to extract additional features based on the newly annotated mentions. 
By iteratively repeating these two steps, we propagate information from a small number of seeds and learn a robust mention identifier. 
Our results indicate a significant improvement over earlier results in [5]. 

However, for the purpose of studying a scientific community, we argue that it is essential to attend to the significant variability in the way authors express a given concept. 
Our notion of a “concept” needs to capture both minor differences in expressing the concept (“SVMs” and “support vector classifiers”) and levels of granularity (such as “support vector machines” and “large margin classifiers”). 
Existing techniques such as topic models [1] do not support the ability to categorize mentions and, as we show, do not allow one to generate tight enough clusters or provide the level of granularity needed to support a careful analysis of the scientific literature. 
Similarly, naive mention clustering based on lexical similarity also does not support grouping mentions to semantically coherent concepts. 
Our second contribution is a new clustering algorithm that makes use of citation contexts as a way to group concept mentions to meaningful coherent concepts. 
Given a citation to paper p, we assume that two mentions m1, m2 of a given category (e.g., TECHNIQUE) appear in the citation context in a way that indicates both m1 and m2 are described in p. 
In this case, we assume a degree of similarity between the two mentions.